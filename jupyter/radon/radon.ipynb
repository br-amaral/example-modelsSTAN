{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d8dbef4",
   "metadata": {},
   "source": [
    "# Multi-level regression modeling, baby one more time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512471ec",
   "metadata": {},
   "source": [
    "This notebook provides an introduction to multi-level regression modeling\n",
    "using [Stan](https://mc-stan.org) and the [CmdStanPy](https://mc-stan.org/cmdstanpy/) interface,\n",
    "a pure Python3 package for Linux, MacOS, and Windows.\n",
    "It is based on Chris Fonnesbeck's excellent [A Primer on Bayesian Multilevel Modeling using PyStan](https://mc-stan.org/users/documentation/case-studies/radon.html), which was developed as part of a [Stan workshop](https://statmoddev.stat.columbia.edu/2016/06/09/a-primer-on-bayesian-multilevel-modeling-using-pystan/)  for biomedical statisticians at Vanderbilt University.\n",
    "The data and models are taken from chapter 12 of the book _Data Analysis Using Regression and Multilevel/Hierarchical Models_, by Andrew Gelman and Jennifer Hill, Cambridge university press, 2006,\n",
    "which is based on a study by [Price and Gelman](http://www.stat.columbia.edu/~gelman/research/published/sagtufinal.pdf).\n",
    "\n",
    "A secondary aim of this notebook is to demonstrate best practices of Bayesian data analysis,\n",
    "which entails careful summaries and visualization of the data, models, and resulting inferences.\n",
    "To visualize data and inference results we use\n",
    "[plotnine](https://plotnine.readthedocs.io/en/stable/).\n",
    "Plotnine is an implementation of a _grammar of graphics_ in Python, based on [ggplot2](https://en.wikipedia.org/wiki/Ggplot2).\n",
    "A grammar of graphics is a general scheme for data visualization which breaks up graphs into semantic components.\n",
    "In plotnine, a ggplot object takes as arguments a [pandas](https://pandas.pydata.org/docs/index.html)\n",
    "DataFrame object and a mapping between Python variables and graph elements.\n",
    "This mapping is the \"aethetic\", denoted by argument `aes`.\n",
    "The different ways to visualize the data are called \"geoms\", shorthand for \"geometric objects\".\n",
    "Theme objects control the overall layout and look and feel.\n",
    "Like ggplot2, plotnine provides a rich set of geoms\n",
    "and fine-grained control over all aspects of the plot layout,\n",
    "leading to more effective statisticial communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23be27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries used in this notebook\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "from cmdstanpy import CmdStanModel\n",
    "\n",
    "# setup plot look and feel\n",
    "theme_set(\n",
    "  theme_grey() + \n",
    "  theme(text=element_text(size=10),\n",
    "        plot_title=element_text(size=14),\n",
    "        axis_title_x=element_text(size=12),\n",
    "        axis_title_y=element_text(size=12),\n",
    "        axis_text_x=element_text(size=8),\n",
    "        axis_text_y=element_text(size=8)\n",
    "       )\n",
    ")\n",
    "flip_xlabels = theme(axis_text_x = element_text(angle=90, hjust=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c80d9",
   "metadata": {},
   "source": [
    "The radon data may sometimes trigger spurious warnings from plotnine and CmdStanPy, which we will ignore.  During model development we recommend leaving CmdStanPy logging level at `logging.WARNING`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb55ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress plotnine warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# suppress CmdStanPy warnings\n",
    "import logging\n",
    "from cmdstanpy.utils import get_logger\n",
    "logger = get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d101db6",
   "metadata": {},
   "source": [
    "## Modeling goal: home radon measurement\n",
    "\n",
    "Applied statistical modeling starts with the question we are trying to answer and the available data.\n",
    "We must understand both the data and the analysis goals before proceeding to model building.\n",
    "\n",
    "The goal of the radon study is to provide reasonable estimates\n",
    "of home radon levels in each of the approximately 3000 counties in the United States.\n",
    "Gelman and Hill write\n",
    "\n",
    ">Radon is a carcinogen — a naturally occurring radioactive gas whose decay products are also radioactive — known to cause lung cancer in high concentrations and estimated to cause several thousand lung cancer deaths per year in the United States. The distribution of radon levels in U.S. homes varies greatly, with some houses having dangerously high concentrations. In order to identify the areas with high radon exposures, the Environmental Protection Agency coordinated radon measurements in a random sample of more than 80,000 houses throughout the country.\n",
    "\n",
    "[Radon gas](https://en.wikipedia.org/wiki/Radon) is a product of the slow decay of uranium into lead.  Due to local differences in geology, the level of exposure to radon gas differs from place to place. A common source is uranium-containing minerals in the ground, and therefore it accumulates in subterranean areas such as basements.\n",
    "\n",
    "![How radon enters the home](radon_entry.jpg)\n",
    "Image from https://www.health.state.mn.us/communities/environment/air/radon/index.html\n",
    "\n",
    "The [EPA radon map](https://www.epa.gov/sites/default/files/2015-07/documents/zonemapcolor.pdf) shows the counties of the US, color coded by radon level - red for the highest risk, orange for moderate, and yellow for low.\n",
    "\n",
    "![EPA radon map](epa_radon_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c2dafe",
   "metadata": {},
   "source": [
    "## Study data:  item-level radon, county-level soil uranium levels\n",
    "\n",
    "The data comes from EPA surveys at the state and national level carried out in the 1990s.\n",
    "It is available from the Gelman and Hill [ARM website](http://www.stat.columbia.edu/~gelman/arm/examples/radon/), together with the R scripts used to produce the examples in the book.\n",
    "The study data is in two files.\n",
    "\n",
    "- Home radon measurements, and the floor (ground or basement) where measured from an EPA survey conducted in 1992.\n",
    "The survey data is in file http://www.stat.columbia.edu/~gelman/arm/examples/radon/srrs2.dat.\n",
    "\n",
    "- County level measurements of soil uranium levels in parts per million.\n",
    "The soil uranium data is in file http://www.stat.columbia.edu/~gelman/arm/examples/radon/cty.dat\n",
    "\n",
    "\n",
    "We have downloaded and renamed these files.\n",
    "File `srrs2.dat` is available as  [raw_radon.csv](raw_radon.csv) and\n",
    "file `cty.dat` is available as [raw_uranium.csv](raw_uranium.csv).\n",
    "These names are informative and will sort together in a directory listing.\n",
    "The full EPA dataset has been [archived separately](http://www.stat.columbia.edu/~gelman/arm/examples/radon_complete/).\n",
    "\n",
    "There are a total of 120K home radon measurements from 3000 US counties.\n",
    "The per-county measurements follow the population density; there are few or no measurements\n",
    "for sparsely populated counties, i.e. rural counties and correspondingly more for metropolitan counties.\n",
    "\n",
    "\n",
    "#### Data preprocessing steps\n",
    "\n",
    "There are many tedious steps in assembling the data; these are shown in full detail in [Appendix A](#appendix_a).\n",
    "Data pre-processing consists of the following steps\n",
    "\n",
    "1. Merge the county-level soil uranium level measurment into the house-level radon data.\n",
    "\n",
    "2. Put both outcome and predictors on the log scale, following Gelman and Hill, chapter 4, section 12.\n",
    "\n",
    "3. Restrict the dataset to Minnesota.\n",
    "\n",
    "The Minnesota data is in file [mn_radon.json](mn_radon.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_radon = pd.read_json(r'mn_radon.json')\n",
    "mn_radon[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7a5b75",
   "metadata": {},
   "source": [
    "## Best Practice #1: preliminary data analysis\n",
    "\n",
    "A sometimes overlooked issue when doing model criticism and model comparison is the fact that we are evaluating the fit of the model _to the data_.  The size and shape of the data informs our choice of model.  Finally, the data collected is not always the data expected.  Therefore we start with plots and summaries of the raw data.\n",
    "\n",
    "**First questions: amount of data, variable of interest**\n",
    "\n",
    "As noted as the outset, the measurements per county vary with the population density.  Therefore a logical first question is:  how much data is there for Minnesota?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af7292",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'number of houses: {len(mn_radon)}')\n",
    "print(f'number of counties: {len(mn_radon.county.unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624db8f5",
   "metadata": {},
   "source": [
    "The goal of our analysis is to estimate home radon levels; therefore the outcome variable of interest is `log_radon`.\n",
    "We use the [pandas.DataFrame.describe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) function to get summary statistics over the observed outcome `log_radon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4a1d96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'log_radon summary statistics\\n{mn_radon[\"log_radon\"].describe()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731fd544",
   "metadata": {},
   "source": [
    "**Relationship between radon and floor**\n",
    "\n",
    "As the radon pathways diagram shows, radon comes from the soil, therefore the floor level on which the measurement was taken should be a good predictor of the observed radon level. This is coded as \"0\" for basement and \"1\" for ground floor level.  Most of the homes in the survey have a basement level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0273e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for flr,pct in zip(range(2), [round(x/919*100) for x in mn_radon.groupby(['floor']).size()]):\n",
    "    print(f'{pct}% observations taken on floor {flr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e614fc",
   "metadata": {},
   "source": [
    "The [plotnine geom_histogram](https://plotnine.readthedocs.io/en/stable/generated/plotnine.geoms.geom_histogram.html) provides a visualization of the distribution of home radon measurements in the survey dataset.\n",
    "We use plotnine's [facet_grid](https://plotnine.readthedocs.io/en/stable/generated/plotnine.facets.facet_grid.html#plotnine.facets.facet_gridplot ) to make separate plots for measurements taken in the basement level (floor 0) and ground floor level (floor 1).\n",
    "The histograms clearly show the different amounts of observation (y axis), but the trend in log radon levels (x axis) is unclear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0826913",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(mn_radon, aes('log_radon'))\n",
    "    + geom_histogram(binwidth=0.2)\n",
    "    + xlab(\"log radon levels\") + ylab(\"number of observations\")\n",
    "    + theme(figure_size=(10,4))\n",
    "    + facet_grid(facets='~ floor', labeller='label_both')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98123f42",
   "metadata": {},
   "source": [
    "The plotnine [plotnine geom_point](https://plotnine.readthedocs.io/en/stable/generated/plotnine.geoms.geom_point.html) plots two variables as (x, y) points.  In the following plots, we always plot `log_radon` on the y axis, since it is the outcome variable of interest for this case study.\n",
    "\n",
    "We plot the log_radon levels by floor and add jitter to see the relative difference in the measurements and number of observations taken by floor.  The plot also shows that there are far more measurements taken in the basement than on the ground floor.  It suggests that radon measurements are higher in the basement than on the ground floor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3caf5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(mn_radon, aes('floor', 'log_radon')) \n",
    "    + geom_jitter(width=0.1) + theme(figure_size=(6,4))\n",
    "    + ggtitle(\"Radon measurements by floor\")\n",
    "    + scale_x_continuous(breaks=range(0,2), minor_breaks=[])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba351d0",
   "metadata": {},
   "source": [
    "**County-level information: number of observations, soil uranium**\n",
    "\n",
    "At the county level we have many home radon measurements from the relatively few counties with metropolitan areas, and very few home radon measurements from the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of per-county measurements, summaries\n",
    "obs_per_county = mn_radon['county'].value_counts(sort=False)\n",
    "uranium_per_county = mn_radon.drop_duplicates(subset='log_uranium')['log_uranium']\n",
    "county_df = pd.DataFrame.from_dict(\n",
    "    {\"county\": obs_per_county.index, \"obs\": obs_per_county.values, \"log_uranium\": uranium_per_county.values}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'summary stats for per-county observations\\n{county_df.obs.describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f910669",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(county_df)\n",
    "    + geom_histogram(aes('obs'), bins=100)\n",
    "    + theme(figure_size=(12,3))\n",
    "    + ylab(\"\") + xlab(\"observations per county\")\n",
    "    + geom_text(county_df[county_df['obs'] > 25], aes(x='obs', y=2, label='county'), size=8,\n",
    "               nudge_x=4, nudge_y=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c77628d",
   "metadata": {},
   "source": [
    "**Relationship between home radon and county-level soil uranium**\n",
    "\n",
    "At the county-level, we have information on the soil uranium level.  We plot the number of observations by soil uranium.  The points on the x-axis line up with the histogram bars on the above plot, but instead of histogram bars, we have a series of points showing the different log_uranium levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9928fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot, keeping uranium level on y axis\n",
    "(ggplot(county_df, aes(x='obs', y='log_uranium'))\n",
    "    + geom_point()\n",
    "    + geom_text(county_df[county_df['obs']>25], aes(label='county'),  size=8, nudge_x=4, nudge_y=0.1)\n",
    "    + ylab(\"county soil log_uranium\") + xlab(\"observations per county\")\n",
    "    + theme(figure_size=(12,3))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a74cb8",
   "metadata": {},
   "source": [
    "We plot the relationship between soil uranium level and the home radon measurement, faceted by floor.\n",
    "Because the soil uranium level measurement is the same for all homes in a county, for counties with many houses, i.e., metropolitan areas, the plot shows distinct vertical bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af92e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(mn_radon, aes('log_uranium', 'log_radon')) + geom_point() +\\\n",
    "    ylab(\"home log_radon\") + xlab(\"county-level soil log_uranium\") + theme(figure_size=(12,4)) +\\\n",
    "    facet_grid(facets='~ floor', labeller='label_both')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b9680b",
   "metadata": {},
   "source": [
    "For many counties, all observations were taken at the basement level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52749055",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Counties with observations from both basement and ground floors: \\\n",
    "{len(mn_radon[mn_radon[\"floor\"] == 1][\"county\"].value_counts())}')\n",
    "\n",
    "print(f'Total number of counties: {mn_radon.county.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f833b025",
   "metadata": {},
   "source": [
    "To see whether or not the soil uranium level might be a good predictor of the home radon measurements, we plot the per-county activity levels, ordered by uranium level per county, descending.\n",
    "We use the [plotnine.geom_boxplot](https://plotnine.readthedocs.io/en/stable/generated/plotnine.geoms.geom_boxplot.html#plotnine.geoms.geom_boxplot)\n",
    "to generate a [box_and_whiskers plot](https://en.wikipedia.org/wiki/Box_plot) for each set of per-county radon measurements.  The width of the box is proportional to the square root of the number of observations, making it easy to see the relatively few counties with a large population.\n",
    "\n",
    "Given the sparse data, the resulting plot is inconclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb04f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uranium_desc = county_df.sort_values(by='log_uranium', ascending=False).reset_index()\n",
    "\n",
    "(ggplot(mn_radon, aes('county', 'log_radon'))\n",
    "    + geom_boxplot(varwidth=True, outlier_alpha=0.4)\n",
    "    + scale_x_discrete(limits=uranium_desc['county']) +  flip_xlabels\n",
    "    + ggtitle(\"Counties ordered by soil uranium high (left) to low (right)\")\n",
    "    + ylab(\"range of home radon measurements\")\n",
    "    + theme(figure_size=(12,6))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977534a0",
   "metadata": {},
   "source": [
    "## Linear regression review (chapters 2 and 3 of Gelman and Hill)\n",
    "\n",
    "> Linear regression is a method that summarizes how the average values of a numerical outcome variable vary over subpopulations defined by linear functions of predictors. ... Regression can be used to predict an outcome given a linear function of these predictors, and regression coefficients can be thought of as comparisons across predicted values or as comparisons among averages in the data. </br>_Gelman and Hill, chapter 3_\n",
    "\n",
    "[Linear regression](https://en.wikipedia.org/wiki/Linear_regression#Formulation) models the relationship between a scalar response and one or more explanatory variables.\n",
    "\n",
    "<img width=\"190\" alt=\"Linear least squares example2\" align=\"right\" style=\"vertical-align:middle;margin:0px 50px\"\n",
    "     src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/53/Linear_least_squares_example2.png/190px-Linear_least_squares_example2.png\">\n",
    "\n",
    "In linear regression, the observations (red) are assumed to be the result of random deviations (green) from an underlying relationship (blue) between a dependent variable (y) and an independent variable (x).\n",
    "\n",
    "A [simple linear regression](https://en.wikipedia.org/wiki/Simple_linear_regression) is a model which relates\n",
    "a pair of sample points, an  _independent variable_ x, and a _dependent variable_ y.\n",
    "The adjective simple refers to the fact that the outcome variable is related to a single predictor.\n",
    "The model finds a linear function (a non-vertical straight line) that,\n",
    "as accurately as possible, predicts the dependent variable values as a function of the independent variable.  (Geometry review: a straight line is defined by its _intercept_ on the x-axis and _slope_, i.e. $y = a + b x$)\n",
    "\n",
    "**Linear regression:  two ways to write the model**\n",
    "\n",
    "The goal of inference is to learn from incomplete or imperfect data.\n",
    "In the simple linear regression model, the error term $\\epsilon$ accounts for imperfect measurments of the data.\n",
    "\n",
    "$\n",
    "y_i = \\alpha \\, + {\\beta}\\,x_i + {\\epsilon}_i\n",
    "$\n",
    "where the errors ${\\epsilon}_i$ have independent normal distributions with mean $0$ and standard deviation $\\sigma$.\n",
    "\n",
    "An equivalent representation is\n",
    "\n",
    "$\n",
    "y_i ∼ \\mathrm{N}(\\alpha + \\beta\\,\\mathrm{X}_i,\\, \\sigma^2), \\ \\ \\ \\mathrm{for}\\ i=1, ..., n\n",
    "$\n",
    "\n",
    "\n",
    "**Simple linear regression model in Stan**\n",
    "\n",
    "The simple linear regression with a single predictor and a slope and intercept coefficient and normally distributed noise is the first model discussed in the [Stan User's Guide Regression Models chapter](https://mc-stan.org/docs/stan-users-guide/linear-regression.html).\n",
    "\n",
    "```\n",
    "data {\n",
    "  int<lower=0> N;\n",
    "  vector[N] x;\n",
    "  vector[N] y;\n",
    "}\n",
    "parameters {\n",
    "  real alpha;\n",
    "  real beta;\n",
    "  real<lower=0> sigma;\n",
    "}\n",
    "model {\n",
    "  y ~ normal(alpha + beta * x, sigma);\n",
    "}\n",
    "```\n",
    "\n",
    "Stan provides [vectorized](https://mc-stan.org/docs/functions-reference/vectorization.html#vectorization) versions of all univariate probability distributions, allowing us to write\n",
    "\n",
    "```\n",
    "y ~ normal(alpha + beta * x, sigma);\n",
    "```\n",
    "\n",
    "which is far more efficient than using a `for` loop over all $x_i$ and $y_i$ pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3349cc2",
   "metadata": {},
   "source": [
    "## Best Practice #2: start with a simple model\n",
    "\n",
    "Starting from a simple model ensures that there is a good baseline\n",
    "against which to measure performance.\n",
    "Gelman and Hill start from a simple linear regression which models the relationship between\n",
    "the log radon measurement and the floor on which this measurement was taken.\n",
    "\n",
    "The **complete pooling** model pools all measurements from all counties.\n",
    "While it's possible to fit this model in Stan, we can also do this in plotnine by adding\n",
    "[plotnine.geom.geom_smooth(method=\"lm\")](https://plotnine.readthedocs.io/en/stable/generated/plotnine.geoms.geom_smooth.html#plotnine.geoms.geom_smooth)\n",
    "to the earlier scatter plot of radon measurements by floor.\n",
    "The black line is the estimated mean and the the grey margins indicate the amount of variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38aaefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(mn_radon, aes('floor', 'log_radon')) + geom_jitter(width=0.05) + theme(figure_size=(5,4)) +\\\n",
    " ggtitle(\"Complete pooling\") + scale_x_continuous(breaks=range(0,2), minor_breaks=[]) +\\\n",
    " geom_smooth(method='ols')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c552b0",
   "metadata": {},
   "source": [
    "If we add faceting to this plot, we are fitting 85 individual regressions.  Given the sparsity of the data, this is a non-starter. There are 25 counties where all measurements were taken on the basement level; for these counties, the trend line is absent. For the remaining counties, most of which have very few measurments, in several instances, e.g., counties \"Lyon\" and \"Redwood\", the regression line between floor 0 and 1 has a positvie slope; in contrast to the complete pooling model. This goes against what we know about how radon enters the home.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(mn_radon, aes('floor', 'log_radon')) + geom_jitter(width=0.05) + theme(figure_size=(18,50)) +\\\n",
    " ggtitle(\"Complete pooling\") + scale_x_continuous(breaks=range(0,2), minor_breaks=[]) +\\\n",
    " geom_smooth(method='ols') + facet_wrap('county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9386c9",
   "metadata": {},
   "source": [
    "### Simple linear regression in Stan:  complete pooling model\n",
    "\n",
    "The complete pooling model is one which doesn't use county information, that is, all counties are the same, and it fits a single regression line to all 919 observations in the dataset. \n",
    "The Stan model in the ARM repository corresponds to the simple linear regression model above,\n",
    "except that it adds a weak prior on the variance term `sigma`.\n",
    "\n",
    "We create a [CmdStanModel](https://mc-stan.org/cmdstanpy/api.html#cmdstanmodel) object from the Stan program file\n",
    "[radon_complete_pool.stan](https://github.com/stan-dev/example-models/blob/master/ARM/Ch.12/radon_complete_pool.stan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d423534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_pooling_model = CmdStanModel(stan_file=os.path.join('stan', 'radon_complete_pool.stan'))\n",
    "print(complete_pooling_model.code())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e913735",
   "metadata": {},
   "source": [
    "We assemble a Python dictionary which contains the definitions of the data block variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b18f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "radon_data = {\"N\": len(mn_radon), \"x\": mn_radon.floor.astype(float), \"y\": mn_radon.log_radon}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873e69e2",
   "metadata": {},
   "source": [
    "We call the model's [sample](https://mc-stan.org/cmdstanpy/api.html#cmdstanpy.CmdStanModel.sample)\n",
    "method which runs Stan's NUTS-HMC sampler.\n",
    "The results are returned in the form of a\n",
    "[CmdStanMCMC](https://mc-stan.org/cmdstanpy/api.html#cmdstanpy.CmdStanMCMC) container object which\n",
    "provides methods to summarize and diagnose the model fit and accessor methods to access the entire sample or individual items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_pooling_fit = complete_pooling_model.sample(data=radon_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a754da06",
   "metadata": {},
   "source": [
    "The CmdStanMCMC object provides accessor methods which return the set of draws for each model variable.\n",
    "\n",
    "+ [draws] returns the entire sample as either a 2D or 3D numpy.ndarray.\n",
    "\n",
    "+ [draws_pd] returns the entire sample as a\n",
    "a [pandas.Dataframe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html).\n",
    "\n",
    "+ [draws_xr] returns an [xarray Drawset](https://docs.xarray.dev/en/stable/generated/xarray.Dataset.html)\n",
    "\n",
    "+ [stan_variable](https://mc-stan.org/cmdstanpy/api.html#cmdstanpy.CmdStanMCMC.stan_variable) method\n",
    "returns a structured [numpy.ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html),\n",
    "and \n",
    "[stan_variables](https://mc-stan.org/cmdstanpy/api.html#cmdstanpy.CmdStanMCMC.stan_variables)\n",
    "returns a Python dict from variable names to numpy.ndarrays.\n",
    "\n",
    "Because we are going to be plotting the results with plotnine, we use the `draws_pd` method to extract the model parameters `alpha`, `beta`, and `sigma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_pd = complete_pooling_fit.draws_pd(vars=['alpha', 'beta', 'sigma'])\n",
    "pool_stats = pool_pd.describe()\n",
    "pool_stats.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f523136",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = (ggplot(mn_radon, aes('floor', 'log_radon')) + geom_jitter(width=0.05)\n",
    " + theme(figure_size=(5,4))\n",
    " + ggtitle(\"Complete pooling\")\n",
    " + scale_x_continuous(breaks=range(0,2), minor_breaks=[])\n",
    " + stat_function(fun=lambda x: pool_stats.alpha['mean'] + pool_stats.beta['mean']*x,\n",
    "               color='blue')\n",
    ")\n",
    "plot\n",
    "# now add 50 lines based on draws from the posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35258575",
   "metadata": {},
   "source": [
    "### Simple linear regression in Stan:  no pooling model\n",
    "\n",
    "The simple no-pooling model as described in Gelman and Hill chapter 12.3\n",
    "does not pool the estimates for the intercept term `alpha`\n",
    "but it does completely pool estimates for the slope coefficient `beta`,\n",
    "i.e., `beta` has the same value across all groups,\n",
    "and also assumes the residual variance is the same within each group.\n",
    "\n",
    "$\n",
    "y_i = \\alpha_{j[i]} \\, + {\\beta}\\,x_i + {\\epsilon}_i\n",
    "$\n",
    "where $j = 1 \\ldots 85$\n",
    "\n",
    "Coding this model in Stan requires the following modifications to the complete pooling model\n",
    "\n",
    "* we introduce data variable `J`, the number of counties.\n",
    "* we introduce data variable `county`, the array of per-house county ids.\n",
    "* we change `alpha` from a scalar to a vector of length is `J`, the number of counties.\n",
    "* we compute an intermediate variable `eta` so that we can continue to use the\n",
    "vectorized form of the sampling statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0037a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger().setLevel(logging.WARN)\n",
    "no_pooling_model = CmdStanModel(stan_file=os.path.join('stan', 'radon_no_pool.stan'))\n",
    "print(no_pooling_model.code())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aafd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "radon_data[\"J\"] = 85\n",
    "radon_data[\"county\"] = mn_radon.county_code + 1\n",
    "\n",
    "no_pooling_fit = no_pooling_model.sample(data=radon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pool_pd = no_pooling_fit.draws_pd(vars=['alpha', 'beta', 'sigma'])\n",
    "no_pool_stats = no_pool_pd.describe()\n",
    "no_pool_stats.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5314d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot alpha plus/minus 1 sd to show rel between amount of data and uncertainty\n",
    "no_pool_alpha = []\n",
    "for i in range(len(county_df)):\n",
    "    vals = [county_df['county'][i], \n",
    "            no_pool_stats.iloc[1, i], \n",
    "            no_pool_stats.iloc[1, i] + no_pool_stats.iloc[2, i],\n",
    "            no_pool_stats.iloc[1, i] - no_pool_stats.iloc[2, i]]\n",
    "    no_pool_alpha.append(vals)\n",
    "no_pool_alpha_pd = pd.DataFrame(no_pool_alpha, columns=['county', 'mean', 'upper', 'lower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114086ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sort order\n",
    "pop_desc = county_df.sort_values(by='obs', ascending=False).reset_index()\n",
    "\n",
    "# visualize\n",
    "(ggplot()\n",
    " # Range strip\n",
    " + geom_segment(\n",
    "     no_pool_alpha_pd,\n",
    "     aes(x='county', xend='county', y='lower', yend='upper'),\n",
    "     size=1.4,\n",
    "     color='darkblue',\n",
    "     alpha=0.5,\n",
    " )\n",
    " + geom_point(no_pool_alpha_pd, aes(x='county', y='mean'))\n",
    " + geom_hline(yintercept=pool_stats.alpha[1], color='darkorange', size=1.5)\n",
    " + scale_x_discrete(limits=pop_desc['county'])\n",
    " + ggtitle(\"No pooling model estimates for alpha (basement log_radon level)\")\n",
    " + ylab(\"central 67% interval\") + xlab(\"ordered by observations per county, desc\")\n",
    " + flip_xlabels\n",
    " + theme(figure_size=(12,4)) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6808b62",
   "metadata": {},
   "source": [
    "The complete pooling model ignores the county level variance.  The no-pooling model overstates the variance between counties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f8442",
   "metadata": {},
   "source": [
    "## Multilevel models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99e6f5a",
   "metadata": {},
   "source": [
    "Multilevel models are extensions of regression in which data are structured in groups and coefficients can vary by group, and both the group-level and individual level co-efficients are modeled.\n",
    "For a simple linear regression model with a single predictor, the complete-pooling model\n",
    "estimates two parameters:  the intercept and slope of the regression line.\n",
    "A multilevel regression model has group-level parameters\n",
    "which provide partial pooling of information across the groups,\n",
    "and which themselve can be modeled.\n",
    "There are three possible ways to pool information:\n",
    "\n",
    "- varying slope, single intercept\n",
    "\n",
    "- single slope, varying intercept\n",
    "\n",
    "- individual slope, individual intercept\n",
    "\n",
    "As we add more predictors to the model, the number of modeling choices increases.\n",
    "\n",
    "For the radon dataset, houses are located within counties, and different counties have different geological profiles, i.e., different amounts of soil uranaium.  There are several ways to partially pool this information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fc84fc",
   "metadata": {},
   "source": [
    "**Model 2A:  verying slope, single intercept** same baseline, different counties have different floor effects\n",
    "\n",
    "**Model 2B: single slope varying intercept** floor effect is the same, different counties have different baseline\n",
    "\n",
    "**Model 2C: varying slope, varying intercept** lots of little indices everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334269f7",
   "metadata": {},
   "source": [
    "<a id='appendix_A'></a>\n",
    "## Appendix A:  Data preprocessing\n",
    "\n",
    "We use pandas to read each CSV file into a [pandas DataFrame](https://pandas.pydata.org/docs/reference/frame.html),\n",
    "which is a tabular data structure, similar that an [R data.frame](https://stat.ethz.ch/R-manual/R-devel/library/base/html/data.frame.html) or a SQL database table.\n",
    "There are many possible ways to manipulate tabular datasets in Python.\n",
    "We borrow code from both Chris Fonnesbeck's PyStan primer and a similar notebook\n",
    "on [multilevel modeling with TensorFlow Probability]( https://notebook.community/tensorflow/probability/tensorflow_probability/examples/jupyter_notebooks/Multilevel_Modeling_Primer), section 3.  Following the latter, we encapsulate step 2 into a function which can be used to restrict the dataset to any state.\n",
    "\n",
    "\n",
    "\n",
    "#### Extract relevant columns from CSV as pandas DataFrame\n",
    "\n",
    "We leverage the [pandas.read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) function\n",
    "to extract the information we need from the raw CSV files with the following non-default arguments\n",
    "\n",
    "* parameter `usecols` allows us to extract just the relevant columns for this analysis.\n",
    "* parameter `skipinitialspace` strips out initial whitespace from the data.\n",
    "\n",
    "Once instantiated, we call the [convert_dtypes method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.convert_dtypes.html) on the newly instantiated dataframe in order to ensure that we can do merge and join operations on all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ddc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radon = pd.read_csv(r'raw_radon.csv',\n",
    "    usecols=['state', 'stfips', 'floor', 'activity', 'county', 'cntyfips'],\n",
    "    skipinitialspace=True,    # CSV file has spaces after delimiter, ignore them\n",
    ").convert_dtypes()\n",
    "print(f'Total records: {len(df_radon)}')\n",
    "df_radon[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7caed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uranium = pd.read_csv(r'raw_uranium.csv',\n",
    "                        usecols=['stfips', 'ctfips', 'st', 'cty', 'Uppm'],\n",
    "                        skipinitialspace=True,\n",
    "                        ).drop_duplicates().convert_dtypes()\n",
    "df_uranium[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3b292c",
   "metadata": {},
   "source": [
    "#### Combine datasets\n",
    "\n",
    "[FIPS code](https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt) are numbers which uniquely identify geographic areas. Both datasets have codes for the state and county ids, but these need to be combined to get a national-level county FIPS code.\n",
    "\n",
    "First we add this common code to both tables, then we use it to merge the county-level soil uranium levels into the radon survey data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab749d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radon['fips'] = df_radon.stfips*1000 + df_radon.cntyfips\n",
    "df_uranium['fips'] = df_uranium.stfips*1000 + df_uranium.ctfips\n",
    "\n",
    "df_radon = df_radon.merge(df_uranium[['fips', 'Uppm']], on='fips')\n",
    "df_radon[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3861a54",
   "metadata": {},
   "source": [
    "#### Put data on log scale\n",
    "\n",
    "Following Gelman and Hill chapter 4, section 4, we work with data on the log scale.\n",
    "We know from geology that both radon measurements and soil uranium levels are always greater than zero,\n",
    "however a few radon measurements in the EPA dataset are 0.\n",
    "In order to be able to work with these measurements on the log scale, we replace 0 with 0.1,\n",
    "which corresponds to a low radon level (following Gelman and Hill)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efacb3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radon['radon'] = df_radon.activity.apply(lambda x: x if x > 0. else 0.1)\n",
    "df_radon['log_radon'] = np.log(df_radon['radon'])\n",
    "\n",
    "df_radon['uranium'] = df_radon.Uppm.apply(lambda x: x if x > 0. else 0.1)\n",
    "df_radon['log_uranium'] = np.log(df_radon['uranium'])\n",
    "df_radon[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96d723b",
   "metadata": {},
   "source": [
    "#### Cleanup (optional)\n",
    "\n",
    "Remove the columns which contain redundant information.  (_Note_: we could also drop columns 'radon' and 'uranium' since we'll be working on the log scale.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99337e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radon.drop(columns=['stfips', 'activity', 'cntyfips', 'Uppm', 'radon', 'uranium'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6863a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radon[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e04b66",
   "metadata": {},
   "source": [
    "#### Helper function: get one state's worth of data\n",
    "\n",
    "It is straightforward to subset the radon data at the state level.\n",
    "Following the TensorFlow Probability notebook, we define a function which given a state code and a dataframe\n",
    "returns a dataframe for that state.\n",
    "\n",
    "We use conditional expressions to [filter specific rows of a dataframe](https://pandas.pydata.org/docs/getting_started/intro_tutorials/03_subset_data.html#how-do-i-filter-specific-rows-from-a-dataframe).\n",
    "We also create a 0-based indices for the state-level individual observations and counties.\n",
    "This makes it easy to iterate through and plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fab763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_filter(df_radon: pd.DataFrame, state: str) -> pd.DataFrame:\n",
    "    df_radon_st = df_radon[df_radon['state']==state].reset_index(drop=True)\n",
    "    counties = sorted(df_radon_st.county.unique())\n",
    "    df_radon_st['county_code'] = df_radon_st.county.astype(pd.api.types.CategoricalDtype(categories=counties)).cat.codes\n",
    "    return df_radon_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radon_mn = state_filter(df_radon, 'MN')\n",
    "df_radon_mn[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9b945d",
   "metadata": {},
   "source": [
    "#### Save to JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851891c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment as needed\n",
    "df_radon_mn.to_json(r'mn_radon.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead6c92",
   "metadata": {},
   "source": [
    "<a id='appendix_B'></a>\n",
    "## Appendix B:  Dataframe operations\n",
    "\n",
    "There are many ways to count, sort, select, and otherwise manipulate the contents of a pandas.Dataframe.\n",
    "Here we list the various operations used in this notebook.\n",
    "\n",
    "#### Count unique\n",
    "\n",
    "\n",
    "wtf?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d68e6",
   "metadata": {},
   "source": [
    "## Appendix C:  Stan tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06387fc5",
   "metadata": {},
   "source": [
    "* it uses the more efficient [`normal_id_glm` distribution](https://mc-stan.org/docs/functions-reference/normal-id-glm.html) instead of the `normal` distribution. The `normal_id_glm` distribution is optimized for simple linear regresion models and takes as arguments:\n",
    "\n",
    "    + a vector of observations of length `N`\n",
    "    + a matrix of predictors of size `[N, M]`\n",
    "    + the scalar intercept parameter\n",
    "    + a vector of length `M` regression coefficients\n",
    "    + variance parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a324f22c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
